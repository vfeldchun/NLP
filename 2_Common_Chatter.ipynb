{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c64093-a692-4cfb-94b2-225d2e2c79a5",
   "metadata": {},
   "source": [
    "# Загрузка и обучение модели общей болталки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b9d98-a23f-4bff-865b-ff8525a0edf6",
   "metadata": {},
   "source": [
    "## Загрузим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1285b7e0-5c0e-4f28-8b7a-08626ee5bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mmap\n",
    "import re\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fc8e4e-1494-46ed-ad23-dff774ef3bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bcd03-9479-4adf-8ad8-7c8892220532",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Определим необходимые функции и классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4550a2-f2f2-47be-a22b-765c2a2dbabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция возвращает количество строк в текстовом файле\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f2fad3-98f9-47f6-a913-ce497ed39894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция предобработки текста\n",
    "def preprocess_txt(line):\n",
    "    # Удаляем HTML теги\n",
    "    spls = re.sub('<[^<]+?>', ' ', line)\n",
    "    # Удаляем URLs\n",
    "    spls = re.sub(r'http\\S+', ' ', spls)\n",
    "    # Удаляем \\t табуляцию\n",
    "    spls = re.sub('\\t', ' ', spls)\n",
    "    # Убираем специальные символы: избавляемся от всего, что не является \"словами\"\n",
    "    spls = re.sub('[^a-zA-Zа-яА-ЯёЁ0-9\\s!?-]', ' ', spls)\n",
    "    # Удаляем многократное повторение букв\n",
    "    spls = re.sub(r\"\\а+\", 'а', spls)\n",
    "    spls = re.sub(r\"\\у+\", 'у', spls)\n",
    "    spls = re.sub(r\"\\к+\", 'к', spls)\n",
    "    spls = re.sub(r\"\\ы+\", 'ы', spls)\n",
    "    # Убираем лишние пробелы\n",
    "    spls = re.sub(r\"\\s\\s+\", ' ', spls)\n",
    "    spls = spls.lower()\n",
    "    if not spls:\n",
    "        spls = np.nan\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda4093a-d7bc-4109-a122-f00aff47f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_val_data(q_data, a_data):\n",
    "    output_data = []\n",
    "    for idx in tqdm(range(q_data.shape[0])):\n",
    "        question = q_data.iloc[idx]\n",
    "        answer = a_data.iloc[idx]\n",
    "        output_data.append(\"\\nq:\" + question + \"\\na:\" + answer)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123f1d48-8288-4246-aedd-da6ca4f918d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonChatterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_text):\n",
    "        self.tokenized_text = tokenized_text\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {q: a[idx].clone().detach() for q, a in self.tokenized_text.items()}\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_text[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b938834d-b317-409d-a10e-4340dfb0e9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция генерирующая ответ на вопрос пользователя\n",
    "def respond_to_dialog(texts, model, tokenizer):\n",
    "    prefix = '\\nq:'\n",
    "    for i, t in enumerate(texts):\n",
    "        prefix += t\n",
    "        prefix += '\\nq:' if i % 2 == 1 else '\\na:'\n",
    "    #print(prefix)\n",
    "    tokens = tokenizer(prefix, return_tensors='pt')\n",
    "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "    end_token_id = tokenizer.encode('\\n')[0]\n",
    "    size = tokens['input_ids'].shape[1]\n",
    "    output = model.generate(\n",
    "        **tokens, \n",
    "        eos_token_id=end_token_id,\n",
    "        do_sample=True, \n",
    "        max_length=size+128, \n",
    "        repetition_penalty=3.2, \n",
    "        temperature=1,\n",
    "        num_beams=3,\n",
    "        length_penalty=0.01,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    decoded = tokenizer.decode(output[0])\n",
    "    result = decoded[len(prefix):]\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2356cc-46ee-4974-89dd-5ef1ea5a916d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция запускающая и поддерживающая диалог с пользователем\n",
    "def start_dialog(tokenizer, model):\n",
    "    seed = input('Начните диалог с ботом любой фразой\\n Для завершения диалога введите: Stop\\n')\n",
    "    history = [seed]\n",
    "    is_continue_dilog = True\n",
    "    \n",
    "    while is_continue_dilog:\n",
    "        if seed == 'Stop':\n",
    "            break\n",
    "            \n",
    "        output = respond_to_dialog([seed], model, tokenizer)\n",
    "        seed = input(output + '\\n')\n",
    "        \n",
    "        history.append(output)\n",
    "        history.append(seed)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c3bdb-4412-4aed-aa91-b6650cccf8e5",
   "metadata": {},
   "source": [
    "## Загрузка и предобработка текста вопросов-ответов для болталки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc46af7-2065-4e8c-a7f5-a4350793cfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4d3ed2eaca4993bb648453e9b44cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7550926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Преобразуем файл вопросов ответов в два списка вопросов и ответов\n",
    "# при этом будем создавать пару вопрос + и первый ответ\n",
    "data_q = []\n",
    "data_a = []\n",
    "\n",
    "is_question = False\n",
    "is_answer = False\n",
    "\n",
    "file_path_from = \"Otvety.txt\"\n",
    "\n",
    "n_line = get_num_lines(file_path_from)\n",
    "with open(\"Otvety.txt\", \"r\", encoding=\"UTF-8\") as fin:\n",
    "    for i in tqdm(range(n_line)):\n",
    "        line = fin.readline()\n",
    "        if line.startswith(\"---\"):\n",
    "            is_question = True\n",
    "            is_answer = False\n",
    "            continue\n",
    "        elif is_question and (not is_answer):\n",
    "            question = line.strip()\n",
    "            is_answer = True\n",
    "            continue\n",
    "        elif is_question and is_answer:\n",
    "            answer = line.strip()\n",
    "            \n",
    "            data_q.append(question)\n",
    "            data_a.append(answer)\n",
    "            \n",
    "            is_question = False\n",
    "            is_answer = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1a4f5-2cd8-4a57-8335-0892641be519",
   "metadata": {},
   "source": [
    "Сохраним вопросы и ответы в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c6c72e-cd8a-4f93-b255-c91c496bf23a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qa = pd.DataFrame(data_q[:10000], columns=['question'])\n",
    "data_qa['answer'] = data_a[:10000]\n",
    "data_qa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec77567-3f28-4e9c-99e6-6e64b50dd911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО...</td>\n",
       "      <td>хомячка....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как парни относятся к цветным линзам? Если у д...</td>\n",
       "      <td>меня вобще прикалывает эта тема :).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что делать, сегодня нашёл 2 миллиона рублей? .</td>\n",
       "      <td>Если это \"счастье \" действительно на вас свали...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  вопрос о ТДВ)) давно и хорошо отдыхаем)) ЛИЧНО...   \n",
       "1  Как парни относятся к цветным линзам? Если у д...   \n",
       "2     Что делать, сегодня нашёл 2 миллиона рублей? .   \n",
       "\n",
       "                                              answer  \n",
       "0                                        хомячка....  \n",
       "1                меня вобще прикалывает эта тема :).  \n",
       "2  Если это \"счастье \" действительно на вас свали...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qa.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87312aff-6c5d-4521-8c6a-0b92f1642caf",
   "metadata": {},
   "source": [
    "Предобработаем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d9c654-c15a-430a-9d21-bb092017147b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a5cae846c44cadb6665519f6ee176e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8a49c9a9344d6a93e9abbd0b022329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_qa['question'] = data_qa['question'].progress_apply(preprocess_txt)\n",
    "data_qa['answer'] = data_qa['answer'].progress_apply(preprocess_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3722cbb-3178-4c9d-9d8e-bdc45d1d4fbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Удаляем строки с пустым ответом или вопросом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3763ce-da37-4c9d-851d-2b583e100f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_qa.dropna(inplace=True)\n",
    "data_qa.reset_index(inplace=True)\n",
    "data_qa.drop(labels=['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de961b28-2282-487b-b13e-cae188302ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffbb5970-ec33-49f9-ba7c-c855c8cef593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное количество слов в вопросах: 3947 и ответах: 45756\n",
      "Среднее количество слов в вопросах: 125.5285 и ответах: 308.3286\n",
      "Минимальное количество слов в вопросах: 1 и ответах: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Максимальное количество слов в вопросах: {} и ответах: {}\"\n",
    "      .format(np.max([len(text) for text in data_qa['question']]), np.max([len(text) for text in data_qa['answer']])))\n",
    "print(\"Среднее количество слов в вопросах: {} и ответах: {}\"\n",
    "      .format(np.mean([len(text) for text in data_qa['question']]), np.mean([len(text) for text in data_qa['answer']])))\n",
    "print(\"Минимальное количество слов в вопросах: {} и ответах: {}\"\n",
    "      .format(np.min([len(text) for text in data_qa['question']]), np.min([len(text) for text in data_qa['answer']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10743581-c143-485c-b607-41cf67e3c61c",
   "metadata": {},
   "source": [
    "Добавляем метку класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "398b95a1-b2d9-4183-a5b0-597d04685408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_qa[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41004a81-f17a-42f8-96c9-624b902f5e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вопрос о тдв давно и хорошо отдыхаем лично вам...</td>\n",
       "      <td>хомячка</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>как парни относятся к цветным линзам? если у д...</td>\n",
       "      <td>меня вобще прикалывает эта тема</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>что делать сегодня нашёл 2 миллиона рублей?</td>\n",
       "      <td>если это счастье действительно на вас свалилос...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>эбу в двенашке называется итэлма что за эбу?</td>\n",
       "      <td>эбу электронный блок управления двигателем авт...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>академия вампиров сколько на даный момент част...</td>\n",
       "      <td>4 охотники и жертвы ледяной укус поцелуй тьмы ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  вопрос о тдв давно и хорошо отдыхаем лично вам...   \n",
       "1  как парни относятся к цветным линзам? если у д...   \n",
       "2       что делать сегодня нашёл 2 миллиона рублей?    \n",
       "3      эбу в двенашке называется итэлма что за эбу?    \n",
       "4  академия вампиров сколько на даный момент част...   \n",
       "\n",
       "                                              answer  class  \n",
       "0                                           хомячка       1  \n",
       "1                   меня вобще прикалывает эта тема       1  \n",
       "2  если это счастье действительно на вас свалилос...      1  \n",
       "3  эбу электронный блок управления двигателем авт...      1  \n",
       "4  4 охотники и жертвы ледяной укус поцелуй тьмы ...      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df70ab-6bd9-4744-83da-1126dd8cda9c",
   "metadata": {},
   "source": [
    "Сохраним датафрейм в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e9cc10-94ee-4c99-b9bb-fdb55a9fd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qa.to_csv('common_talker_data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ed68e-89c2-48a4-9c66-3706de8b0e71",
   "metadata": {},
   "source": [
    "#### Разобьем ответы на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "819516d9-2629-4273-8e1d-7aa091c7a0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_q, test_q, train_a, test_a = train_test_split(data_qa.question, data_qa.answer, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc390e5-9e8b-42ea-8ec9-5e507ef7a327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 8000\n",
      "Размер тестовой выборки: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер обучающей выборки: \"+ str(len(train_q)))\n",
    "print(\"Размер тестовой выборки: \"+ str(len(test_q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687446d-d1e9-4b94-9267-a6250e526c57",
   "metadata": {},
   "source": [
    "#### Преобразуем обучающие и тестовые данные для токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "668c614c-dadf-4f2d-b5bd-a156e6fe31af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af2ba4f316a4c0cb0ee6dee5460952f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6cd42ed110409aa7453d3a10234d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = build_train_val_data(train_q, train_a)\n",
    "test_dataset = build_train_val_data(test_q, test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ecd77-b9b9-4e71-85e6-95d9f50b247e",
   "metadata": {},
   "source": [
    "#### Выполним токенизацию обучающей и тестовой выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b83df56-f3dd-40ac-9f5c-15b7d8dd025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_model_name = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
    "tokenizer_sd = AutoTokenizer.from_pretrained(sber_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bac0f91-19cb-4d5e-8fb3-857b739a60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_sd.pad_token = tokenizer_sd.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55d12ace-8bed-4251-9c56-278000be15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.9 s\n",
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_train_dataset = tokenizer_sd(train_dataset, padding=\"max_length\", truncation=True, max_length=512, return_tensors='pt')\n",
    "tokenized_test_dataset = tokenizer_sd(test_dataset, padding=\"max_length\", truncation=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec589b4-2465-4fdc-a37b-3d8879ee3033",
   "metadata": {},
   "source": [
    "#### Преобразуем в стандартный датасет torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9219b2a-9ff9-4995-baf6-5e338ded3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_pt = CommonChatterDataset(tokenized_train_dataset)\n",
    "test_dataset_pt = CommonChatterDataset(tokenized_test_dataset)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer_sd, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71651510-79ad-459c-a272-f572c3acbc7c",
   "metadata": {},
   "source": [
    "## Загрузка и дообучение модели болталки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275f4a0-4bb9-4153-b389-51475ddda85b",
   "metadata": {},
   "source": [
    "### Загрузка предобученой модели GPT3 от SberDevices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687c02bb-649b-4f4f-b9a2-f7dfc2670914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_sd = AutoModelForCausalLM.from_pretrained(sber_model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85748d-629f-42ef-abd8-b2a210fbc82f",
   "metadata": {},
   "source": [
    "### Дообучение модели на наших данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48cba9b-0d10-4554-9195-16d9c519f6d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Определяем аргументы для Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aeda9ef-b98d-48be-b0aa-e35e19272e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2-sd-up\", # Выходной каталог\n",
    "    overwrite_output_dir=True, # устанавливаем перезапись конткнта в выходном каталоге\n",
    "    num_train_epochs=4, # nколичество эпох обучения\n",
    "    per_device_train_batch_size=3, # размер батча для обучения\n",
    "    per_device_eval_batch_size=4,  # размер батча для проверки\n",
    "    eval_steps = 400, #  Количество шагов между оценками\n",
    "    save_steps=800, # полсе # шага модель сохраняется\n",
    "    warmup_steps=500,# количество шагов для планировщика шага обучения\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69b71c-463e-467a-8b1b-f5e79b317510",
   "metadata": {},
   "source": [
    "#### Создаем Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae14e9aa-1960-4910-85ff-40c9c92cc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_sd,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset_pt,\n",
    "    eval_dataset=test_dataset_pt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc431b6-cd34-457b-bc1e-a4ef9a0b55ff",
   "metadata": {},
   "source": [
    "#### Производим дообучение и сохраняем полученную модель и токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70ff20b2-7ee6-4736-9134-666a6f2bd18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10668' max='10668' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10668/10668 28:19, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.479600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.054900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.744300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.716200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.734900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.741400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10668, training_loss=3.3130955848078805, metrics={'train_runtime': 1700.8922, 'train_samples_per_second': 18.814, 'train_steps_per_second': 6.272, 'total_flos': 8361345024000000.0, 'train_loss': 3.3130955848078805, 'epoch': 4.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12ca3cb9-246e-4d40-9960-410a435e19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('trainer_ct_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9febc6e7-8eca-459f-bee4-c906b982d157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_sd.save_pretrained('final_ct_gpt_tk')\n",
    "model_sd.save_pretrained('final_ct_gpt_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f9817-e5fd-4298-a788-57412ce44b81",
   "metadata": {},
   "source": [
    "### Загрузка модели и ткенайзера и проверка работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6192c059-b2e6-4e3f-94f9-02af756dca9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_fsd = AutoTokenizer.from_pretrained(\"final_ct_gpt_tk\")\n",
    "model_fsd = AutoModelForCausalLM.from_pretrained(\"final_ct_gpt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c0353c7-5db9-4e26-8892-4ad3ec5a99f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Начните диалог с ботом любой фразой\n",
      " Для завершения диалога введите: Stop\n",
      " Привет!\n",
      "ты кто?\n",
      " Гость\n",
      "уважаемый гость! мы не виделись с вами это может быть связано с какими-то делами?\n",
      " Да был в командировке\n",
      "был!!! а что там нового???\n",
      " Что делать если я нашел миллион рублей?\n",
      "выиграй в лотерею и купи себе новый айфон!\n",
      " Тебе наравятся цветные линзы?\n",
      "вроде нет!!! но думаю что не исключено!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      " Чем ты сейчас занимаешся?\n",
      "спать ложусь!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!!\n",
      " Спокойной ночи!\n",
      "доброго!\n",
      " Stop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Привет!',\n",
       " 'ты кто?',\n",
       " 'Гость',\n",
       " 'уважаемый гость! мы не виделись с вами это может быть связано с какими-то делами?',\n",
       " 'Да был в командировке',\n",
       " 'был!!! а что там нового???',\n",
       " 'Что делать если я нашел миллион рублей?',\n",
       " 'выиграй в лотерею и купи себе новый айфон!',\n",
       " 'Тебе наравятся цветные линзы?',\n",
       " 'вроде нет!!! но думаю что не исключено!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!',\n",
       " 'Чем ты сейчас занимаешся?',\n",
       " 'спать ложусь!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!! ы!!!',\n",
       " 'Спокойной ночи!',\n",
       " 'доброго!',\n",
       " 'Stop']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_dialog(tokenizer_fsd, model_fsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02b5c9-f8d8-4979-bb85-b9eb769eeedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
